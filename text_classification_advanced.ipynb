{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaynk4ToI/p9mUiNIVtKTv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pmadhyastha/INM434/blob/main/text_classification_advanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Text processing with linear and non-linear models\n",
        "\n"
      ],
      "metadata": {
        "id": "tFCRVxAcueH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "__author__ = \"Pranava Madhyastha\" \n",
        "__version__ = \"INM434/IN3045 City, University of London, Spring 2023\""
      ],
      "metadata": {
        "id": "upBFFf0wukHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importance of features\n",
        "\n",
        "We will begin with experimets on features. But before we begin, let us download datasets library from huggingface which gives us access to a large number of datasets. \n",
        "\n",
        "We will locally install the library (this is temporary and will disappear as soon the session is restarted). "
      ],
      "metadata": {
        "id": "6Kbca122lNaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preparation\n",
        "!pip install datasets # we are installing huggingface datasets"
      ],
      "metadata": {
        "id": "i1EXjybwlaNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the dataset and experimenting with features\n",
        "\n",
        "For the following set of worked out examples we will work with sentiment portion of the tweet_eval dataset. Read the documentation for the dataset here: https://huggingface.co/datasets/tweet_eval. \n",
        "\n",
        "The function load_dataset automatically creates the pre-designed split of train and test. This helps in proper comparison of the models. \n",
        "\n",
        "We will first begin with linear model (logistic regression) and play with different types of features on the same dataset. \n",
        "\n",
        "Please attempt the TODOs mentioned in the code below."
      ],
      "metadata": {
        "id": "wvTwwfN7KSCA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UZCF1A9-j9j6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Custom feature extraction function\n",
        "\n",
        "# TODO - Experiments with features: \n",
        "#   1. Experiment with different ngrams\n",
        "#   2. Read the documentation for CountVectorizer - see what happens with the analyzer argument? \n",
        "#   3. Try changing max_df and min_df \n",
        "#   4. Try changing max_features\n",
        "#   5. What happens when you binarise the features? \n",
        "#   6. Experiment stopwords. See the impact of stop words. \n",
        "#   7. Experiment with lower casing tokens \n",
        "#   8. Advanced - can you write a new preprocessor function - this goes inside CountVectorizer. \n",
        "\n",
        "def custom_feature_extraction(text, ngrams=3, compute=0, vectorizer=None):\n",
        "    if compute:\n",
        "    # Extract unigrams, bigrams, and trigrams\n",
        "        vectorizer = CountVectorizer(ngram_range=(1, ngrams))\n",
        "        features = vectorizer.fit_transform(text)\n",
        "        return features, vectorizer\n",
        "    else: \n",
        "        features = vectorizer.transform(text)\n",
        "        return features\n",
        "    \n",
        "\n",
        "# Load sentiment analysis dataset from Hugging Face\n",
        "dataset = load_dataset('tweet_eval', 'sentiment')\n",
        "\n",
        "# Extract input and output data\n",
        "X = dataset['train']['text']\n",
        "y = dataset['train']['label']\n",
        "\n",
        "# Split dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "\n",
        "# Further split training set into smaller training set and validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=123)\n",
        "\n",
        "\n",
        "# Extract features using custom feature extraction function\n",
        "X_train_feats, feat_extractor = custom_feature_extraction(X_train, compute=1)\n",
        "X_val = custom_feature_extraction(X_val, compute=0, vectorizer=feat_extractor)\n",
        "X_test = custom_feature_extraction(X_test, compute=0, vectorizer=feat_extractor)\n",
        "\n",
        "# Train linear model with logistic regression\n",
        "clf = LogisticRegression(verbose=True)\n",
        "clf.fit(X_train_feats, y_train)\n",
        "\n",
        "# Evaluate model on validation set\n",
        "val_score = clf.score(X_val, y_val)\n",
        "print('Validation score:', val_score)\n",
        "\n",
        "# Evaluate model on test set\n",
        "test_score = clf.score(X_test, y_test)\n",
        "print('Test score:', test_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot the learning curves\n",
        "\n",
        "Let us now see how the learning curves vary with different design choices of the features. \n"
      ],
      "metadata": {
        "id": "vxTTe9WWHnbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "\n",
        "X_train_ngrams_1, feat_extractor = custom_feature_extraction(X_train, ngrams=1, compute=1)\n",
        "X_train_ngrams_2, feat_extractor = custom_feature_extraction(X_train, ngrams=2, compute=1)\n",
        "X_train_ngrams_3, feat_extractor = custom_feature_extraction(X_train, ngrams=3, compute=1)\n",
        "X_train_ngrams_4, feat_extractor = custom_feature_extraction(X_train, ngrams=4, compute=1)\n",
        "\n",
        "\n",
        "\n",
        "# Calculate learning curve\n",
        "train_sizes_1, train_scores_1, cv_scores_1 = learning_curve(clf, X_train_ngrams_1, y_train, cv=5, train_sizes=[0.1, 0.3, 0.5, 0.7, 0.9])\n",
        "#train_sizes_2, train_scores_2, cv_scores_2 = learning_curve(clf, X_train_ngrams_2, y_train, cv=5, train_sizes=[0.1, 0.3, 0.5, 0.7, 0.9])\n",
        "#train_sizes_3, train_scores_3, cv_scores_3 = learning_curve(clf, X_train_ngrams_3, y_train_sample, cv=5, train_sizes=[0.1, 0.3, 0.5, 0.7, 0.9])\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(train_sizes_1, cv_scores_1.mean(axis=1), label='Cross-validation score for clf-1')\n",
        "#plt.plot(train_sizes_2, cv_scores_2.mean(axis=1), label='Cross-validation score for clf-2')\n",
        "\n",
        "\n",
        "plt.title('Learning curve')\n",
        "plt.xlabel('Training set size')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "y7jdR-2vmVrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO\n",
        "1. Plot all the variants of different feature designs. \n",
        "2. Experiment with SVM inplace of Logistic Regression. \n",
        "3. What is the loss for SVM? \n",
        "4. Test your classifiers on a different sentiment dataset from hugginface. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "83t_Lq9CHzVO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Non-linear models\n",
        "\n",
        "We will only cover multi-layer perceptron (a feed-forward model) in this lab. \n",
        "\n",
        "We will first make use of scikit-learn's MLP classifier. \n",
        "\n",
        "Let us build a simple 2 hidden layer feedforward model with ReLU non-linearity. "
      ],
      "metadata": {
        "id": "2sWUkmaYI2Vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset into training and testing sets (validation splits) \n",
        "# It is always a good idea to have validation set - this is where we will tune the hyperparameters. \n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(dataset['train']['text'], dataset['train']['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# One-hot encode the text using CountVectorizer and calculate the mean pooling\n",
        "vectorizer = CountVectorizer(binary=True)\n",
        "train_data = vectorizer.fit_transform(train_texts)\n",
        "train_data = train_data.multiply(1 / train_data.sum(axis=1)) # what is happening here? \n",
        "\n",
        "val_data = vectorizer.transform(val_texts)\n",
        "val_data = val_data.multiply(1 / val_data.sum(axis=1))\n",
        "\n",
        "# Build the neural network model with two hidden layers\n",
        "model = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', max_iter=5, verbose=True)\n",
        "\n",
        "# Train the model\n",
        "\n",
        "model.fit(train_data, train_labels)\n",
        "train_acc = accuracy_score(train_labels, model.predict(train_data))\n",
        "val_acc = accuracy_score(val_labels, model.predict(val_data))\n",
        "\n",
        "print(train_acc, val_acc)"
      ],
      "metadata": {
        "id": "JvAgZsgqw1A1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO \n",
        "\n",
        "1. Evaluate the new model on the original test set. \n",
        "2. Is it taking a long time to train? Why? \n",
        "3. Can you experiment with different features? \n",
        "4. Is this model better? \n",
        "5. What would you change? (the hyperparameters) - how are these different from \"feature combination\" based design choices? \n",
        "6. Can you perform model comparison with hypothesis testing? "
      ],
      "metadata": {
        "id": "OtKeh3ZbJSVA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using pytorch + GPU acceleration \n",
        "\n",
        "THe code below reimplements the non-linear model using pytorch. We will be using GPU, to set the environment to GPU please change the runtime type and select the runtime with standard GPU. \n",
        "\n",
        "Try going back to CPU. Increase the batch size. "
      ],
      "metadata": {
        "id": "fqMVr3W-Py-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "\n",
        "# This line of code assigns the device that will be used for running of the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define a custom dataset class\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, vocab):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Convert the text to a one-hot encoding\n",
        "        text = self.vocab.transform([self.texts[idx]])\n",
        "        text = text.multiply(1 / text.sum(axis=1))\n",
        "\n",
        "        # Calculate the mean pooling of the one-hot encoding\n",
        "        text = torch.tensor(text.todense()[0])\n",
        "        text = torch.mean(text, dim=0)\n",
        "\n",
        "        # Convert the label to a tensor\n",
        "        label = torch.tensor(self.labels[idx])\n",
        "\n",
        "        return text, label\n",
        "\n",
        "# Define a custom neural network model\n",
        "class SentimentModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
        "        super(SentimentModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
        "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# One-hot encode the texts using CountVectorizer\n",
        "vectorizer = CountVectorizer(binary=True)\n",
        "vectorizer.fit(train_texts)\n",
        "\n",
        "# Define the dataset and data loader for training\n",
        "train_dataset = SentimentDataset(train_texts, train_labels, vectorizer)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Define the dataset and data loader for testing\n",
        "val_dataset = SentimentDataset(val_texts, val_labels, vectorizer)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define the model, loss function, and optimizer\n",
        "model = SentimentModel(input_size=len(vectorizer.vocabulary_), hidden_size1=100, hidden_size2=50, output_size=3).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(5):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs.float().to(device))\n",
        "        loss = criterion(outputs, labels.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print(f\"[Epoch {epoch+1}, Batch {i+1}] Loss: {running_loss/100:.3f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "model.eval()\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "with torch.no_grad():\n",
        "    for data in val_loader:\n",
        "        inputs, labels = data\n",
        "        outputs = model(inputs.float().to(device))\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_samples += labels.size(0)\n",
        "        total_correct += (predicted == labels.to(device)).sum().item()\n",
        "\n",
        "print(f\"Accuracy on test set: {(total_correct/total_samples)*100:.2f}%\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y3urFNGm67nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO \n",
        "\n",
        "1. Experiment with different activation functions. \n",
        "2. Apply the classifier to different sentiment datasets from hugginface. What did you notice? \n",
        "3. Make the classifiers comparable (similar scores) by tuning hyperparameters. \n",
        "4. Are the features still sub-optimal? "
      ],
      "metadata": {
        "id": "2LpXyx3jQiJE"
      }
    }
  ]
}